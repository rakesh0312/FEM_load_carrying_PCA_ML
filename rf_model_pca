import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import KFold, train_test_split
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.decomposition import PCA
import pickle

# Read the data
df = pd.read_excel("F:\Project\matlab\project 9 fem normalised.xlsx")
pd.set_option('display.float_format', lambda x: '%.4f' % x)

# Separate features (x) and target (y)
x = df.values[:, :13]
y = df.values[:, 13]

# Normalize the input data
scaler = StandardScaler()
x_normalized = scaler.fit_transform(x)

# PCA
pca = PCA(n_components=13)
x_pc = pca.fit_transform(x_normalized)
x_pc.shape

# K-fold cross-validation
cv = KFold(n_splits=10, shuffle=True, random_state=123)

# Save the PCA converted input to an Excel file
x_pc_df = pd.DataFrame(x_pc)
x_pc_df.to_excel("pca_input.xlsx", index=False)

# Split data into training and testing sets
x_train_pca, x_test_pca, y_train, y_test = train_test_split(x_pc, y, test_size=0.3, random_state=2)

# RandomForestRegressor
reg = RandomForestRegressor(n_estimators=90,
                           max_depth=12,
                           min_samples_leaf=1,
                           random_state=1)

reg.fit(x_train_pca, y_train)

# Predictions and evaluation
y_train_pred = reg.predict(x_train_pca)
rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))
print("RMSE on training data: %f" % rmse_train)

y_test_pred = reg.predict(x_test_pca)
rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))
print("RMSE on testing data: %f" % rmse_test)

print("R square on training data:", r2_score(y_train, y_train_pred))
print("R square on testing data:", r2_score(y_test, y_test_pred))

# Save the trained model
with open("rf_fem9.pkl", "wb") as file:
    pickle.dump(reg, file)
